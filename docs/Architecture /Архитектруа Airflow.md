# Архитектура Airflow

Через Docker контейнер был развернут **Airflow v.2.10.5** с поддержкой **Python 3.11**.

## Состав контейнера

### 1. PostgreSQL
**PostgreSQL** используется как мета-база данных для хранения служебной информации Airflow, включая данные о DAG-ах, их состоянии, расписаниях, переменных и подключениях.

### 2. Airflow Webserver
**Airflow Webserver** — это UI-исполнение Airflow, предназначенное для запуска, настройки и отладки DAG-ов.

### 3. Airflow Scheduler
**Airflow Scheduler** — блок Airflow, отвечающий за настройку и запуск DAG-ов по расписанию.

## Используемый Executor

Для реализации используется **LocalExecutor**. Этот тип Executor был выбран благодаря возможностям параллельного выполнения задач и небольшой рабочей нагрузке, так как количество таблиц и данных в них не превышает 1 Тб. **LocalExecutor** также предоставляет гибкость в переключении на другие типы Executor-ов, что дает хорошие возможности для масштабирования в будущем.

### Executor (Исполнитель)
Executor — это абстракция, управляющая тем, где и как запускаются задачи в Airflow.

#### Типы Executor:
- **SequentialExecutor:**  
  Работает на одном процессе и выполняет задачи последовательно. Используется для локальной разработки и тестирования.
- **LocalExecutor:**  
  Выполняет задачи параллельно, используя несколько процессов. Подходит для небольших задач и небольшой рабочей нагрузки.
- **CeleryExecutor:**  
  Использует очередь задач (RabbitMQ или Redis) и несколько воркеров для выполнения задач. Отлично подходит для распределенных систем с высокой нагрузкой.
- **KubernetesExecutor:**  
  Каждая задача запускается в отдельном Kubernetes-поде. Используется для облачных решений.

## Подробности о компонентах

### PostgreSQL
**Назначение:**  
Служит основным хранилищем метаданных для Airflow. В нем сохраняются данные о DAG-ах, заданиях, состоянии выполнения и другой служебной информации.

**Характеристики:**
- Запускается на официальном образе `postgres:15`.
- Конфигурируется с помощью переменных окружения (пользователь, пароль, имя базы данных).
- Доступен по порту 5432.
- Использует том `postgres_data` для постоянного хранения данных, что обеспечивает сохранность информации между перезапусками контейнера.

**Сетевое взаимодействие:**
- Подключен к внешней сети `my_network`, что позволяет другим компонентам Airflow (веб-сервер и планировщик) подключаться к базе данных.

---

### Airflow Webserver
**Назначение:**  
Обеспечивает веб-интерфейс для мониторинга, управления и администрирования рабочих процессов (DAG-ов) в Airflow.

**Характеристики:**
- Собирается с использованием кастомного Dockerfile, что позволяет задать специфичные настройки и зависимости.
- При старте выполняет обновление базы данных (`airflow db upgrade`) и создает пользователей (Admin и Guest) для первоначальной конфигурации.
- Работает с **LocalExecutor**, что подходит для небольших и средних нагрузок.
- Обеспечивает подключение к базе данных через переменную `AIRFLOW__DATABASE__SQL_ALCHEMY_CONN`.
- Использует разделяемые тома для хранения DAG-ов, логов, плагинов и конфигурационных файлов.
- Доступен по порту 8080 для внешних запросов к веб-интерфейсу.

**Сетевое взаимодействие:**
- Запущен в сети `my_network`, что позволяет общаться с Postgres и другими компонентами Airflow.

---

### Airflow Scheduler
**Назначение:**  
Отвечает за планирование задач: мониторинг DAG-ов, определение готовности задач к выполнению и их запуск.

**Характеристики:**
- Собирается из того же Dockerfile, что и веб-сервер.
- Работает с **LocalExecutor** для планирования и запуска задач на одном узле.
- Использует те же тома, что и веб-сервер, для синхронизации конфигураций и данных.
- Подключается к Postgres для чтения и записи метаданных, необходимых для корректного выполнения задач.

**Сетевое взаимодействие:**
- Также функционирует в сети `my_network`, обеспечивая прямой доступ к базе данных и синхронизацию с веб-сервером.

---

## Особенности архитектуры

### Сетевая инфраструктура
Все сервисы объединены в общую внешнюю сеть `my_network`, что позволяет обеспечить стабильное соединение между компонентами и организовать централизованное управление коммуникацией между контейнерами. Эта сеть также предоставляет подключение к любой базе данных, развернутой локально или на том же сервере.

### Тома (Volumes)
Использование общих томов для хранения данных (DAG-ов, логов, плагинов, конфигурационных файлов) обеспечивает:
- Сохранение данных при перезапуске контейнеров.
- Единообразный доступ к данным для всех сервисов Airflow.

Для работы Airflow были добавлены следующие тома:
- `sql` — папка для хранения всех исполняемых SQL-скриптов, задействованных в DAG-ах.
- `dags` — папка для хранения всех DAG-ов.
- `config` — папка для хранения конфигурационных таблиц для забора данных.

### Использование переменных окружения и `.env` файла
Позволяет централизованно управлять параметрами конфигурации (например, настройки подключения к базе данных, ключи безопасности, учетные данные пользователей) без необходимости пересобирать образы.

---

## Преимущества микросервисной архитектуры

Архитектура решения построена по принципу **микросервисов**, где каждая основная функция (хранение метаданных, веб-интерфейс и планирование задач) реализована в отдельном контейнере. Реализованный подход обеспечивает:
- **Изоляцию и модульность:** Каждый сервис отвечает за свою функцию, что упрощает обслуживание и обновление компонентов.
- **Масштабируемость:** Использование Docker позволяет быстро развертывать дополнительные экземпляры при росте нагрузки.
- **Удобство управления:** Разделяемые тома и централизованное управление переменными окружения обеспечивают согласованность данных и конфигураций между сервисами.


<image src="https://github.com/NikGerasimovich98/Data-cluster/blob/main/docs/Architecture%20/Pics/Airflow-arch.drawio.png" alt="Архитектура Airflow">
