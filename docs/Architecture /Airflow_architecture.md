# Архитектура Airflow

В данном документе описана архитектура решения с использованием **Airflow v.2.10.5**, развернутого через Docker с поддержкой **Python 3.11**.

## Состав контейнера

### 1. **PostgreSQL**
PostgreSQL используется как мета-база данных для хранения служебной информации Airflow. В ней хранятся данные о DAG-ах, их состоянии, расписаниях, переменных, подключениях и других служебных данных.

- **Характеристики:**
  - Запускается на официальном образе `postgres:15`.
  - Настроен с использованием переменных окружения: пользователь, пароль, имя базы данных.
  - Доступен по порту 5432.
  - Использует том `postgres_data` для постоянного хранения данных, что обеспечивает их сохранность между перезапусками контейнера.
  - Подключен к внешней сети `my_network`, что позволяет другим компонентам Airflow подключаться к базе данных.

### 2. **Airflow Webserver**
Webserver представляет собой UI-часть Airflow, предназначенную для настройки, запуска и отладки DAG-ов.

- **Характеристики:**
  - Собирается с использованием кастомного Dockerfile.
  - При старте выполняет обновление базы данных с помощью команды `airflow db upgrade`.
  - Создает пользователей (Admin и Guest) для первоначальной конфигурации.
  - Работает с **LocalExecutor**, что подходит для небольшой и средней нагрузки.
  - Обеспечивает подключение к базе данных через переменную окружения `AIRFLOW__DATABASE__SQL_ALCHEMY_CONN`.
  - Монтирует общие тома для хранения DAG-ов, логов, плагинов и конфигурационных файлов.
  - Доступен через веб-интерфейс по порту 8080.

### 3. **Airflow Scheduler**
Scheduler отвечает за планирование задач, мониторинг DAG-ов и запуск задач по расписанию.

- **Характеристики:**
  - Собирается из того же Dockerfile, что и webserver, для обеспечения согласованной среды.
  - Работает с **LocalExecutor** для планирования и запуска задач локально.
  - Использует те же тома, что и webserver, для синхронизации конфигураций и данных.
  - Подключается к PostgreSQL для работы с метаданными.
  - Запускается в сети `my_network` для обеспечения связи с другими сервисами.

---

## Типы Executors

Executor — это абстракция в Airflow, которая управляет тем, где, как и какие задачи запускаются.

### 1. **SequentialExecutor**
- Работает на одном процессе и выполняет задачи последовательно.
- Используется в основном для локальной разработки и тестирования.

### 2. **LocalExecutor**
- Выполняет задачи параллельно, используя несколько процессов.
- Подходит для небольших задач с небольшой рабочей нагрузкой.

### 3. **CeleryExecutor**
- Использует очередь задач (RabbitMQ или Redis) и несколько воркеров для выполнения задач.
- Подходит для распределенных систем с высокой нагрузкой.

### 4. **KubernetesExecutor**
- Каждая задача запускается в отдельном Kubernetes-поде.
- Используется для облачных решений и масштабируемых систем.

---

## Архитектурные особенности

### Сетевая инфраструктура:
Все сервисы Airflow объединены в общую сеть `my_network`, что обеспечивает стабильное соединение между компонентами и возможность подключения к любой базе данных, развернутой локально или на том же сервере.

### Тома (Volumes):
Использование общих томов для хранения данных (DAG-ов, логов, плагинов, конфигурационных файлов) позволяет:
- Сохранять данные при перезапуске контейнеров.
- Обеспечивать единообразный доступ к данным для всех сервисов Airflow.

Для работы с Airflow добавлены следующие тома:
- `sql` — папка для хранения всех исполняемых SQL-скриптов, задействованных в DAG-ах.
- `dags` — папка для хранения всех DAG-ов.
- `config` — папка для хранения конфигурационных таблиц для забора данных.

### Использование переменных окружения и `.env` файла:
Использование `.env` файла позволяет централизованно управлять параметрами конфигурации, такими как настройки подключения к базе данных, ключи безопасности и учетные данные пользователей, без необходимости пересобирать образы.

---

## Микросервисная архитектура

Архитектура решения построена по принципу микросервисов, где каждая основная функция (хранение метаданных, веб-интерфейс и планирование задач) реализована в отдельном контейнере. Это обеспечивает:
- **Изоляцию и модульность:** каждый сервис отвечает за свою функцию, что упрощает обслуживание и обновление компонентов.
- **Масштабируемость:** Docker позволяет быстро развертывать дополнительные экземпляры при росте нагрузки.
- **Удобство управления:** разделяемые тома и централизованное управление переменными окружения обеспечивают согласованность данных и конфигураций между сервисами.

--- 

<image src="https://github.com/NikGerasimovich98/Data-cluster/blob/main/docs/Architecture%20/Pics/Airflow-arch.drawio.png" alt="Архитектура Airflow">
